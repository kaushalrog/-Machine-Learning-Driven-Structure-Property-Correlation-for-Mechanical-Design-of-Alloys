# -*- coding: utf-8 -*-
"""SVM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BqLKjMhB1JeNqCRmZUhPDcxnxVXlpTx_
"""

# Install required libraries
!pip install -q openpyxl scikit-learn imbalanced-learn seaborn matplotlib pandas

# Import libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import StratifiedKFold
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.inspection import permutation_importance
from imblearn.over_sampling import SMOTE

# Load the dataset
file_path = "/content/HEA_Phase_Dataset_v1d.xlsx"
df = pd.read_excel(file_path)

# Select relevant columns and drop missing values
raw_features = ['Num_of_Elem', 'VEC', 'Atom.Size.Diff', 'Elect.Diff', 'dHmix', 'dSmix', 'Sythesis_Route']
target = 'Phases'
df_clean = df[raw_features + [target]].dropna()

# Encode categorical column
df_clean['Sythesis_Route'] = LabelEncoder().fit_transform(df_clean['Sythesis_Route'])

# Encode target
target_encoder = LabelEncoder()
y = target_encoder.fit_transform(df_clean[target])

# Define X AFTER encoding
X = df_clean[raw_features]

# Update the actual features list used
features = X.columns.tolist()

# Train-test split
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)

# Scale
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# SMOTE
from imblearn.over_sampling import SMOTE
smote = SMOTE(random_state=42)
X_train_bal, y_train_bal = smote.fit_resample(X_train_scaled, y_train)

# Train model
from sklearn.svm import SVC
svc = SVC(kernel='rbf', random_state=42)
svc.fit(X_train_bal, y_train_bal)

# Permutation importance
from sklearn.inspection import permutation_importance

# Double check actual number of features
print("Model was trained on:", X.shape[1], "features")
print("Feature list length:", len(features))

result = permutation_importance(svc, X_test_scaled, y_test, n_repeats=30, random_state=42)
importance = pd.Series(result.importances_mean, index=features).sort_values(ascending=False)

# Plot
import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(8, 5))
sns.barplot(x=importance, y=importance.index, palette='mako')
plt.title('Permutation Feature Importance (SVC)')
plt.xlabel('Mean Importance')
plt.tight_layout()
plt.show()

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Train SVC model
svc = SVC(kernel='rbf', random_state=42)
svc.fit(X_train_scaled, y_train)

# Predict on train and test
y_train_pred = svc.predict(X_train_scaled)
y_test_pred = svc.predict(X_test_scaled)

# Accuracy
train_accuracy = accuracy_score(y_train, y_train_pred)
test_accuracy = accuracy_score(y_test, y_test_pred)

print("Training Accuracy:", train_accuracy)

print("Testing Accuracy:", test_accuracy)

from sklearn.svm import SVC
from sklearn.metrics import balanced_accuracy_score

# Train model
svc = SVC(kernel='rbf', random_state=42)
svc.fit(X_train, y_train)

# Predict
y_pred = svc.predict(X_test)

# Calculate balanced accuracy
balanced_acc = balanced_accuracy_score(y_test, y_pred)
print("Balanced Accuracy:", balanced_acc)

# Classification Reports
print("\n--- Training Classification Report ---\n")
print(classification_report(y_train, y_train_pred, target_names=target_encoder.classes_))

print("\n--- Testing Classification Report ---\n")
print(classification_report(y_test, y_test_pred, target_names=target_encoder.classes_))

# Confusion Matrices
train_cm = confusion_matrix(y_train, y_train_pred)
test_cm = confusion_matrix(y_test, y_test_pred)

# Plot confusion matrix heatmaps
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

sns.heatmap(train_cm, annot=True, fmt='d', cmap='Greens',
            xticklabels=target_encoder.classes_, yticklabels=target_encoder.classes_, ax=axes[0])
axes[0].set_title('Training Confusion Matrix')
axes[0].set_xlabel('Predicted')
axes[0].set_ylabel('Actual')

sns.heatmap(test_cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=target_encoder.classes_, yticklabels=target_encoder.classes_, ax=axes[1])
axes[1].set_title('Testing Confusion Matrix')
axes[1].set_xlabel('Predicted')
axes[1].set_ylabel('Actual')

plt.tight_layout()
plt.show()

